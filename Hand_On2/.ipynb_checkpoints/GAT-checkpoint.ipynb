{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7da03cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.data import register_data_args\n",
    "from dgl.data import CoraGraphDataset, CiteseerGraphDataset, PubmedGraphDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c2bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        score = acc\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "        return self.early_stop\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), 'es_checkpoint.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb085cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 num_classes,\n",
    "                 heads,\n",
    "                 activation,\n",
    "                 feat_drop,\n",
    "                 attn_drop,\n",
    "                 negative_slope,\n",
    "                 residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        # input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads[0],\n",
    "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
    "        # hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads[l],\n",
    "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
    "        # output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads[-1],\n",
    "            feat_drop, attn_drop, negative_slope, residual, None))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = inputs\n",
    "        for l in range(self.num_layers):\n",
    "            h = self.gat_layers[l](self.g, h).flatten(1)\n",
    "        # output projection\n",
    "        logits = self.gat_layers[-1](self.g, h).mean(1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ffd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    _, indices = torch.max(logits, dim=1)\n",
    "    correct = torch.sum(indices == labels)\n",
    "    return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        return accuracy(logits, labels)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # load and preprocess dataset\n",
    "    if args['dataset'] == 'cora':\n",
    "        data = CoraGraphDataset()\n",
    "    elif args['dataset'] == 'citeseer':\n",
    "        data = CiteseerGraphDataset()\n",
    "    elif args['dataset'] == 'pubmed':\n",
    "        data = PubmedGraphDataset()\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset: {}'.format(args['dataset']))\n",
    "\n",
    "    g = data[0]\n",
    "    if args['gpu'] < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        g = g.int().to(args['gpu'])\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    num_feats = features.shape[1]\n",
    "    n_classes = data.num_classes\n",
    "    n_edges = g.number_of_edges()\n",
    "\n",
    "    # add self loop\n",
    "    g = dgl.remove_self_loop(g)\n",
    "    g = dgl.add_self_loop(g)\n",
    "    n_edges = g.number_of_edges()\n",
    "    # create model\n",
    "    heads = ([args['num_heads']] * args['num_layers']) + [args['num_out_heads']]\n",
    "    model = GAT(g,\n",
    "                args['num_layers'],\n",
    "                num_feats,\n",
    "                args['num_hidden'],\n",
    "                n_classes,\n",
    "                heads,\n",
    "                F.elu,\n",
    "                args['in_drops'],\n",
    "                args['attn_drops'],\n",
    "                args['negative_slope'],\n",
    "                args['residual'])\n",
    "\n",
    "    if args['early_stop']:\n",
    "        stopper = EarlyStopping(patience=100)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # use optimizer\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "    # initialize graph\n",
    "    dur = []\n",
    "    for epoch in range(args['epochs']):\n",
    "        model.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        # forward\n",
    "        logits = model(features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        train_acc = accuracy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        if args['fastmode']:\n",
    "            val_acc = accuracy(logits[val_mask], labels[val_mask])\n",
    "        else:\n",
    "            val_acc = evaluate(model, features, labels, val_mask)\n",
    "            if args['early_stop']:\n",
    "                if stopper.step(val_acc, model):\n",
    "                    break\n",
    "\n",
    "    if args['early_stop']:\n",
    "        model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "    acc = evaluate(model, features, labels, test_mask)\n",
    "    print(\"Test Accuracy {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe7ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Test Accuracy 0.8310\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    SEED = 22\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED) \n",
    "    args = {}\n",
    "    args['gpu'] = 0\n",
    "    args['epochs'] = 200\n",
    "    args['num_heads'] = 8\n",
    "    args['num_out_heads'] = 1\n",
    "    args['num_layers'] = 1\n",
    "    args['num_hidden'] = 8\n",
    "    args['residual'] = False\n",
    "    args['in_drops'] = 0.6\n",
    "    args['attn_drops'] = 0.6\n",
    "    args['lr'] = 5e-3\n",
    "    args['weight_decay'] = 5e-4\n",
    "    args['negative_slope'] = 0.2\n",
    "    args['dataset'] = 'cora'\n",
    "    args['early_stop'] = False\n",
    "    args['fastmode'] = False\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3937080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Test Accuracy 0.7160\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    SEED = 923\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED) \n",
    "    args = {}\n",
    "    args['gpu'] = 0\n",
    "    args['epochs'] = 200\n",
    "    args['num_heads'] = 8\n",
    "    args['num_out_heads'] = 1\n",
    "    args['num_layers'] = 1\n",
    "    args['num_hidden'] = 8\n",
    "    args['residual'] = False\n",
    "    args['in_drops'] = 0.6\n",
    "    args['attn_drops'] = 0.6\n",
    "    args['lr'] = 5e-3\n",
    "    args['weight_decay'] = 5e-4\n",
    "    args['negative_slope'] = 0.2\n",
    "    args['dataset'] = 'citeseer'\n",
    "    args['early_stop'] = False\n",
    "    args['fastmode'] = False\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73e49e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Test Accuracy 0.7780\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    SEED = 1 \n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED) \n",
    "    args = {}\n",
    "    args['gpu'] = 0\n",
    "    args['epochs'] = 200\n",
    "    args['num_heads'] = 8\n",
    "    args['num_out_heads'] = 1\n",
    "    args['num_layers'] = 1\n",
    "    args['num_hidden'] = 8\n",
    "    args['residual'] = False\n",
    "    args['in_drops'] = 0.6\n",
    "    args['attn_drops'] = 0.6\n",
    "    args['lr'] = 5e-3\n",
    "    args['weight_decay'] = 5e-4\n",
    "    args['negative_slope'] = 0.2\n",
    "    args['dataset'] = 'pubmed'\n",
    "    args['early_stop'] = False\n",
    "    args['fastmode'] = False\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560574b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
